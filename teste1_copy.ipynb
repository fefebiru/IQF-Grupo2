{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f5b26bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import warnings\n",
    "# import quantstats as qs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd256f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "closing_price1 = pd.read_excel('fechamento_limpo.xlsx')\n",
    "print('1')\n",
    "quality1 = pd.read_excel('base_quality_limpa.xlsx')\n",
    "print('1')\n",
    "low_size1 = pd.read_excel('base_low_size_limpa.xlsx')\n",
    "print('1')\n",
    "value1 = pd.read_excel('value_limpo.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8d9fa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_size1[\"Data\"] = pd.to_datetime(low_size1[\"Data\"])\n",
    "low_size1 = low_size1.set_index(\"Data\")\n",
    "\n",
    "quality1[\"Data\"] = pd.to_datetime(quality1[\"Data\"])\n",
    "quality1 = quality1.set_index(\"Data\")\n",
    "\n",
    "value1[\"Data\"] = pd.to_datetime(value1[\"Data\"])\n",
    "value1 = value1.set_index(\"Data\")\n",
    "\n",
    "closing_price1[\"Data\"] = pd.to_datetime(closing_price1[\"Data\"])\n",
    "closing_price1 = closing_price1.set_index(\"Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fe3d04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_ineg1 = pd.read_excel('ineg_limpo (3).xlsx')\n",
    "dados_ineg1['Data'] = pd.to_datetime(dados_ineg1['Data'])\n",
    "dados_ineg1 = dados_ineg1.set_index('Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7aff01eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "initial_date = pd.Timestamp(dt.datetime(2000,1,24))\n",
    "final_date =pd.Timestamp(dt.datetime(2024,12,31))\n",
    "\n",
    "\n",
    "low_size2 = low_size1[(low_size1.index >= initial_date) & (low_size1.index <=final_date)]\n",
    "closing_price2 = closing_price1[(closing_price1.index >= initial_date) & (closing_price1.index <=final_date)]\n",
    "quality2 = quality1[(quality1.index >= initial_date) & (quality1.index <=final_date)]\n",
    "value2 = value1[(value1.index >= initial_date) & (value1.index <=final_date)]\n",
    "dados_ineg2 = dados_ineg1[(dados_ineg1.index >= initial_date) & (dados_ineg1.index <=final_date)]\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "# Força o índice para datetime corretamente\n",
    "closing_price = closing_price1.copy()\n",
    "closing_price.index = pd.to_datetime(closing_price.index, errors='coerce')\n",
    "closing_price = closing_price[closing_price.index.notna()]  # remove datas inválidas\n",
    "\n",
    "\n",
    "low_size = low_size1.copy()\n",
    "low_size.index = pd.to_datetime(low_size.index, errors='coerce')\n",
    "low_size = low_size[low_size.index.notna()]\n",
    "\n",
    "\n",
    "quality = quality1.copy()\n",
    "quality.index = pd.to_datetime(quality.index, errors='coerce')\n",
    "quality = quality[quality.index.notna()]\n",
    "\n",
    "\n",
    "value = value1.copy()\n",
    "value.index = pd.to_datetime(value.index, errors='coerce')\n",
    "value = value[value.index.notna()]\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "# Colocar os lookcbacks de cada estrategia\n",
    "\n",
    "lookback_momentum = 3\n",
    "lookback_low_size = 6\n",
    "lookback_low_vol = 6\n",
    "lookback_quality = 9\n",
    "lookback_value = 6\n",
    "\n",
    "\n",
    "rebal_time = 3  #  1 mes --> unico para toda a carteira\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "closing_price = closing_price2.copy()\n",
    "value = value2.copy()\n",
    "low_size = low_size2.copy() \n",
    "quality = quality2.copy()\n",
    "dados_ineg = dados_ineg2.copy()\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "dados_ineg = dados_ineg.dropna(axis=1, how='all')\n",
    "\n",
    "cutoff_date = initial_date\n",
    "dados_ineg = dados_ineg[dados_ineg.index >= cutoff_date]\n",
    "\n",
    "quality_original = quality.copy()\n",
    "value_original = value.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ceb8b7",
   "metadata": {},
   "source": [
    "# BACKTEST RODANDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "258fdad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Winners</th>\n",
       "      <th>Universo</th>\n",
       "      <th>Losers</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-04-25</th>\n",
       "      <td>1.009323</td>\n",
       "      <td>1.013873</td>\n",
       "      <td>1.011467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-04-26</th>\n",
       "      <td>1.035560</td>\n",
       "      <td>1.016411</td>\n",
       "      <td>1.007206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-04-27</th>\n",
       "      <td>1.042419</td>\n",
       "      <td>1.026533</td>\n",
       "      <td>1.012788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-04-28</th>\n",
       "      <td>1.041556</td>\n",
       "      <td>1.042229</td>\n",
       "      <td>1.025614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-01</th>\n",
       "      <td>1.041556</td>\n",
       "      <td>1.042229</td>\n",
       "      <td>1.025614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-17</th>\n",
       "      <td>118.494801</td>\n",
       "      <td>115.536761</td>\n",
       "      <td>81.818591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-18</th>\n",
       "      <td>118.100373</td>\n",
       "      <td>115.196062</td>\n",
       "      <td>81.703495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-21</th>\n",
       "      <td>118.412633</td>\n",
       "      <td>115.511637</td>\n",
       "      <td>82.131311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-22</th>\n",
       "      <td>117.612324</td>\n",
       "      <td>114.712747</td>\n",
       "      <td>81.760605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-10-23</th>\n",
       "      <td>117.120763</td>\n",
       "      <td>114.520092</td>\n",
       "      <td>81.669141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6295 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Winners    Universo     Losers\n",
       "Data                                         \n",
       "2000-04-25    1.009323    1.013873   1.011467\n",
       "2000-04-26    1.035560    1.016411   1.007206\n",
       "2000-04-27    1.042419    1.026533   1.012788\n",
       "2000-04-28    1.041556    1.042229   1.025614\n",
       "2000-05-01    1.041556    1.042229   1.025614\n",
       "...                ...         ...        ...\n",
       "2024-10-17  118.494801  115.536761  81.818591\n",
       "2024-10-18  118.100373  115.196062  81.703495\n",
       "2024-10-21  118.412633  115.511637  82.131311\n",
       "2024-10-22  117.612324  114.712747  81.760605\n",
       "2024-10-23  117.120763  114.520092  81.669141\n",
       "\n",
       "[6295 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns = pd.DataFrame()\n",
    "\n",
    "while True:\n",
    "\n",
    "    rebal = initial_date + pd.DateOffset(months=rebal_time)\n",
    "    \n",
    "    # print(f\"Initial: {initial_date}, Rebal: {rebal}, Final: {final_date}\")\n",
    "\n",
    "    if rebal <= final_date:\n",
    "         \n",
    "        ineg_date_analysis = initial_date - pd.DateOffset(months=lookback_ibx)\n",
    "        ineg = dados_ineg[(dados_ineg.index < initial_date) & (dados_ineg.index >= ineg_date_analysis)]\n",
    "        ineg2 = ineg.copy()\n",
    "        ineg = ineg.ffill().bfill()\n",
    "\n",
    "        if not ineg.empty:\n",
    "                ineg = ineg.iloc[[-1]].T.reset_index()\n",
    "                ineg.columns = ['ticker', 'neg']\n",
    "        else:\n",
    "                initial_date += pd.DateOffset(months=rebal_time)\n",
    "                continue    # <<<<<< IMPORTANTE AQUI\n",
    "\n",
    "\n",
    "        #era ticket é o nome da ação e neg é o índice de negociabilidade\n",
    "        ineg.columns = ['ticker','neg'] if 'neg' not in ineg.columns else ineg.columns\n",
    "\n",
    "\n",
    "        #no fim essa lista iá significar que as ações investidas estão na lista de boa negociabilidade\n",
    "        ibx_tickers = ineg.sort_values(by='neg', ascending=False).head(100)['ticker'].tolist()\n",
    "\n",
    "    # --------------------------------------------------------------\n",
    "\n",
    "        # OFENSIVA\n",
    "\n",
    "        #momentum:\n",
    "        # Define o intervalo para analisar o desempenho passado das ações\n",
    "        momentum_date_analysis = initial_date - pd.DateOffset(months=lookback_momentum)\n",
    "        # Filtra os preços dentro do intervalo desejado\n",
    "        # print(closing_price)\n",
    "        momentum = closing_price[(closing_price.index < initial_date) & (closing_price.index > momentum_date_analysis)]\n",
    "        # print(momentum)\n",
    "\n",
    "        #cálculo do momentum:\n",
    "        momentum = momentum.pct_change().add(1).cumprod().add(-1)\n",
    "        # Pega apenas a última linha dos retornos acumulados (mais recente)\n",
    "        momentum = momentum.iloc[-1]\n",
    "        # Converte para DataFrame e renomeia as colunas\n",
    "        momentum = momentum.reset_index()\n",
    "        momentum.columns = ['ticker', 'momentum'] #Ticker = nome da ação e value = valor da ação\n",
    "        # print(ibx_tickers)\n",
    "        momentum = momentum[momentum['ticker'].isin(ibx_tickers)]  #Verifica se a ação está entre as top 100 mais negociadas na bolsa \n",
    "\n",
    "        # Ordena da maior performance para a menor\n",
    "        momentum = momentum.sort_values(by='momentum', ascending=False).reset_index(drop=True)\n",
    "        # print(momentum)\n",
    "\n",
    "        # low size em cima de momentum\n",
    "\n",
    "        momentum_20_pc = momentum['momentum'].quantile(0.90) \n",
    "        momentum_20_pc = momentum[momentum['momentum'] >= momentum_20_pc]\n",
    "\n",
    "        acoes_20_momentum = momentum_20_pc['ticker'].tolist()\n",
    "\n",
    "        low_size_date_analysis = initial_date - pd.DateOffset(months=lookback_low_size)\n",
    "        low_size_filtro = low_size[(low_size.index < initial_date) & (low_size.index > low_size_date_analysis)]\n",
    "\n",
    "        if low_size_filtro.empty:\n",
    "            # print(\"Sem dados de low_size para:\", initial_date)\n",
    "            initial_date += pd.DateOffset(months=rebal_time)\n",
    "            continue\n",
    "\n",
    "\n",
    "        low_size_filtro = low_size_filtro.iloc[-1]\n",
    "        low_size_filtro=low_size_filtro.reset_index()\n",
    "        low_size_filtro.columns = ['ticker','low_size']\n",
    "\n",
    "        \n",
    "        low_size_novo = low_size_filtro[low_size_filtro['ticker'].isin(acoes_20_momentum)]\n",
    "        low_size_novo = low_size_novo.sort_values(by='low_size', ascending=True).reset_index(drop=True)\n",
    "\n",
    "        lista_low_size = low_size_novo.ticker.tolist()\n",
    "        \n",
    "        # analisar se faz sentido essa constatação de winners e loosers ou se é ao contrário\n",
    "\n",
    "        limite_winners = low_size_novo.low_size.quantile(0.2)\n",
    "\n",
    "        book_loosers_ofensiva = low_size_novo[low_size_novo['low_size'] > limite_winners]\n",
    "        book_loosers_ofensiva = book_loosers_ofensiva.ticker.tolist()\n",
    "\n",
    "        book_winners_ofensiva = low_size_novo[low_size_novo['low_size'] <= limite_winners]   \n",
    "        book_winners_ofensiva = book_winners_ofensiva.ticker.tolist()\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "        # DEFENSIVA\n",
    "\n",
    "        # low vol\n",
    "\n",
    "        low_vol_date_analysis = initial_date - pd.DateOffset(months=lookback_low_vol)\n",
    "        low_vol_prices = closing_price[(closing_price.index < initial_date) & (closing_price.index > low_vol_date_analysis)]\n",
    "\n",
    "        # Calcula volatilidade (desvio padrão dos retornos)\n",
    "        low_vol = low_vol_prices.pct_change().std()  \n",
    "        low_vol = low_vol.reset_index()\n",
    "        low_vol.columns = ['ticker', 'low_vol']\n",
    "\n",
    "        # Filtra para tickers do IBX\n",
    "        low_vol = low_vol[low_vol['ticker'].isin(ibx_tickers)]\n",
    "        low_vol = low_vol.sort_values(by='low_vol', ascending=True).reset_index(drop=True)\n",
    "\n",
    "        low_vol_score = low_vol.copy()\n",
    "        low_vol_score['score'] = low_vol.index + 1\n",
    "        \n",
    "        lista_low_vol = low_vol.ticker.tolist()\n",
    "\n",
    "\n",
    "        quality_date_analysis = initial_date - pd.DateOffset(months=lookback_quality)\n",
    "        quality = quality_original[(quality_original.index < initial_date) & (quality_original.index > quality_date_analysis)]\n",
    "\n",
    "        if not quality.empty:\n",
    "                quality = quality.iloc[[-1]].T.reset_index()\n",
    "                quality.columns = ['ticker','quality']\n",
    "        else:\n",
    "                initial_date += pd.DateOffset(months=rebal_time)\n",
    "                continue\n",
    "\n",
    "        quality = quality[quality['ticker'].isin(lista_low_vol)]\n",
    "        quality = quality.sort_values(by='quality', ascending=False).reset_index(drop=True)\n",
    "\n",
    "        quality_score = quality.copy()\n",
    "        quality_score['score'] = quality.index + 1\n",
    "\n",
    "        quality_score['score_result'] = quality_score['score'] + low_vol_score['score']\n",
    "        quality_score = quality_score.sort_values(by='score_result', ascending=True).reset_index(drop=True)\n",
    "        lista_quality = quality.ticker.tolist()\n",
    "\n",
    "\n",
    "        acoes_25_quality_low_vol = quality_score.score_result.quantile(0.9)\n",
    "        acoes_25_quality_low_vol = quality_score[quality_score['score_result'] <= acoes_25_quality_low_vol]   \n",
    "        acoes_25_quality_low_vol = acoes_25_quality_low_vol.ticker.tolist()\n",
    "\n",
    "\n",
    "        # value\n",
    "\n",
    "        value_date_analysis = initial_date - pd.DateOffset(months=lookback_value)\n",
    "        value = value_original[(value_original.index < initial_date) & (value_original.index > value_date_analysis)]\n",
    "        value = value.iloc[-1]\n",
    "        value = value.reset_index()\n",
    "        value.columns = ['ticker','value']\n",
    "        value = value[value['ticker'].isin(acoes_25_quality_low_vol)]\n",
    "        value = value.sort_values(by='value', ascending=False).reset_index(drop=True)\n",
    "\n",
    "\n",
    "        limite_winners = value.value.quantile(0.9)\n",
    "\n",
    "        book_winners_defensiva = value[value['value'] >= limite_winners]   \n",
    "        book_winners_defensiva = book_winners_defensiva.ticker.tolist()\n",
    "\n",
    "        book_loosers_defensiva = value[value['value'] < limite_winners]\n",
    "        book_loosers_defensiva = book_loosers_defensiva.ticker.tolist()\n",
    "\n",
    "        # ---------------------------------------------------------------\n",
    "\n",
    "        # Backtest defensiva - winners\n",
    "        backtest_defensiva_w = closing_price[(closing_price.index >= initial_date) & (closing_price.index < rebal)]\n",
    "        backtest_defensiva_w = backtest_defensiva_w[book_winners_defensiva].pct_change().replace(np.nan,0)\n",
    "        backtest_defensiva_w['Retorno'] = backtest_defensiva_w.mean(axis=1)\n",
    "        backtest_defensiva_w_ret = backtest_defensiva_w['Retorno'][1:]\n",
    "\n",
    "        # Backtest ofensiva - winners\n",
    "        backtest_ofensiva_w = closing_price[(closing_price.index >= initial_date) & (closing_price.index < rebal)]\n",
    "        backtest_ofensiva_w = backtest_ofensiva_w[book_winners_ofensiva].pct_change().replace(np.nan,0)\n",
    "        backtest_ofensiva_w['Retorno'] = backtest_ofensiva_w.mean(axis=1)\n",
    "        backtest_ofensiva_w_ret = backtest_ofensiva_w['Retorno'][1:]\n",
    "\n",
    "        # Combina os dois backtests: 80% defensiva + 20% ofensiva\n",
    "        backtest_winners_ret = 0.7 * backtest_defensiva_w_ret + 0.3 * backtest_ofensiva_w_ret\n",
    "\n",
    "        #---------------------------------------------------------------\n",
    "\n",
    "        # Backtest defensiva - loosers\n",
    "        backtest_defensiva_l = closing_price[(closing_price.index >= initial_date) & (closing_price.index < rebal)]\n",
    "        backtest_defensiva_l = backtest_defensiva_l[book_loosers_defensiva].pct_change().replace(np.nan,0)\n",
    "        backtest_defensiva_l['Retorno'] = backtest_defensiva_l.mean(axis=1)\n",
    "        backtest_defensiva_l_ret = backtest_defensiva_l['Retorno'][1:]\n",
    "\n",
    "        # Backtest ofensiva - loosers\n",
    "        backtest_ofensiva_l = closing_price[(closing_price.index >= initial_date) & (closing_price.index < rebal)]\n",
    "        backtest_ofensiva_l = backtest_ofensiva_l[book_loosers_ofensiva].pct_change().replace(np.nan,0)\n",
    "        backtest_ofensiva_l['Retorno'] = backtest_ofensiva_l.mean(axis=1)\n",
    "        backtest_ofensiva_l_ret = backtest_ofensiva_l['Retorno'][1:]\n",
    "\n",
    "        # Combina os dois backtests: 80% defensiva + 20% ofensiva\n",
    "        backtest_loosers_ret = 0.7 * backtest_defensiva_l_ret + 0.3 * backtest_ofensiva_l_ret\n",
    "\n",
    "        # Universo (opcional: você pode manter o universo como todos os tickers do IBX)\n",
    "        backtest_universe = closing_price[(closing_price.index >= initial_date) & (closing_price.index < rebal)]\n",
    "        backtest_universe = backtest_universe[ibx_tickers].pct_change().replace(np.nan,0)\n",
    "        backtest_universe['Retorno'] = backtest_universe.mean(axis=1)\n",
    "        backtest_universe_ret = backtest_universe['Retorno'][1:]\n",
    "\n",
    "        # ----------------------------------------------------------------\n",
    "\n",
    "        # retorno\n",
    "        retorno_rebal = pd.DataFrame({\n",
    "            'Winners': backtest_winners_ret,\n",
    "            'Universo': backtest_universe_ret,\n",
    "            'Losers': backtest_loosers_ret,\n",
    "        })\n",
    "\n",
    "\n",
    "        returns = pd.concat([returns, retorno_rebal], ignore_index=False)\n",
    "\n",
    "        initial_date = initial_date + pd.DateOffset(months=rebal_time)\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "returns = returns.add(1).cumprod()\n",
    "\n",
    "returns\n",
    "# qs.reports.full(returns['Winners'],returns['Universo'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b17bafd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 8, 9, 80, 100)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(book_winners_ofensiva), len(book_loosers_ofensiva), len(book_winners_defensiva), len(book_loosers_defensiva), len(ibx_tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2882269f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.270710480922585"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns.Losers.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47627cdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2000-02-25', '2000-02-28', '2000-02-29', '2000-03-01',\n",
       "               '2000-03-02', '2000-03-03', '2000-03-06', '2000-03-07',\n",
       "               '2000-03-08', '2000-03-09',\n",
       "               ...\n",
       "               '2024-12-10', '2024-12-11', '2024-12-12', '2024-12-13',\n",
       "               '2024-12-16', '2024-12-17', '2024-12-18', '2024-12-19',\n",
       "               '2024-12-20', '2024-12-23'],\n",
       "              dtype='datetime64[ns]', name='Data', length=6180, freq=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "806da68a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Performance Metrics</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid frequency: ME",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32moffsets.pyx:4447\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.offsets._get_offset\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ME'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32moffsets.pyx:4549\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.offsets.to_offset\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32moffsets.pyx:4453\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.offsets._get_offset\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid frequency: ME",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m qs\u001b[38;5;241m.\u001b[39mreports\u001b[38;5;241m.\u001b[39mfull(returns[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWinners\u001b[39m\u001b[38;5;124m'\u001b[39m], returns[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUniverso\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\fetom\\anaconda3\\Lib\\site-packages\\quantstats\\reports.py:554\u001b[0m, in \u001b[0;36mfull\u001b[1;34m(returns, benchmark, rf, grayscale, figsize, display, compounded, periods_per_year, match_dates, **kwargs)\u001b[0m\n\u001b[0;32m    551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _utils\u001b[38;5;241m.\u001b[39m_in_notebook():\n\u001b[0;32m    552\u001b[0m     iDisplay(iHTML(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<h4>Performance Metrics</h4>\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    553\u001b[0m     iDisplay(\n\u001b[1;32m--> 554\u001b[0m         metrics(\n\u001b[0;32m    555\u001b[0m             returns\u001b[38;5;241m=\u001b[39mreturns,\n\u001b[0;32m    556\u001b[0m             benchmark\u001b[38;5;241m=\u001b[39mbenchmark,\n\u001b[0;32m    557\u001b[0m             rf\u001b[38;5;241m=\u001b[39mrf,\n\u001b[0;32m    558\u001b[0m             display\u001b[38;5;241m=\u001b[39mdisplay,\n\u001b[0;32m    559\u001b[0m             mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    560\u001b[0m             compounded\u001b[38;5;241m=\u001b[39mcompounded,\n\u001b[0;32m    561\u001b[0m             periods_per_year\u001b[38;5;241m=\u001b[39mperiods_per_year,\n\u001b[0;32m    562\u001b[0m             prepare_returns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    563\u001b[0m             benchmark_title\u001b[38;5;241m=\u001b[39mbenchmark_title,\n\u001b[0;32m    564\u001b[0m             strategy_title\u001b[38;5;241m=\u001b[39mstrategy_title,\n\u001b[0;32m    565\u001b[0m         )\n\u001b[0;32m    566\u001b[0m     )\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dd, _pd\u001b[38;5;241m.\u001b[39mSeries):\n\u001b[0;32m    569\u001b[0m         iDisplay(iHTML(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<h4 style=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmargin-bottom:20px\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>Worst 5 Drawdowns</h4>\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\fetom\\anaconda3\\Lib\\site-packages\\quantstats\\reports.py:960\u001b[0m, in \u001b[0;36mmetrics\u001b[1;34m(returns, benchmark, rf, display, mode, sep, compounded, periods_per_year, prepare_returns, match_dates, **kwargs)\u001b[0m\n\u001b[0;32m    957\u001b[0m     metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMax Consecutive Losses *int\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _stats\u001b[38;5;241m.\u001b[39mconsecutive_losses(df)\n\u001b[0;32m    959\u001b[0m metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGain/Pain Ratio\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _stats\u001b[38;5;241m.\u001b[39mgain_to_pain_ratio(df, rf)\n\u001b[1;32m--> 960\u001b[0m metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGain/Pain (1M)\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _stats\u001b[38;5;241m.\u001b[39mgain_to_pain_ratio(df, rf, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mME\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    961\u001b[0m \u001b[38;5;66;03m# if mode.lower() == 'full':\u001b[39;00m\n\u001b[0;32m    962\u001b[0m \u001b[38;5;66;03m#     metrics['GPR (3M)'] = _stats.gain_to_pain_ratio(df, rf, \"QE\")\u001b[39;00m\n\u001b[0;32m    963\u001b[0m \u001b[38;5;66;03m#     metrics['GPR (6M)'] = _stats.gain_to_pain_ratio(df, rf, \"2Q\")\u001b[39;00m\n\u001b[0;32m    964\u001b[0m \u001b[38;5;66;03m#     metrics['GPR (1Y)'] = _stats.gain_to_pain_ratio(df, rf, \"YE\")\u001b[39;00m\n\u001b[0;32m    965\u001b[0m metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m~~~~~~~\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m blank\n",
      "File \u001b[1;32mc:\\Users\\fetom\\anaconda3\\Lib\\site-packages\\quantstats\\stats.py:505\u001b[0m, in \u001b[0;36mgain_to_pain_ratio\u001b[1;34m(returns, rf, resolution)\u001b[0m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgain_to_pain_ratio\u001b[39m(returns, rf\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, resolution\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    501\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;124;03m    Jack Schwager's GPR. See here for more info:\u001b[39;00m\n\u001b[0;32m    503\u001b[0m \u001b[38;5;124;03m    https://archive.is/wip/2rwFW\u001b[39;00m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 505\u001b[0m     returns \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39m_prepare_returns(returns, rf)\u001b[38;5;241m.\u001b[39mresample(resolution)\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m    506\u001b[0m     downside \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m(returns[returns \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msum())\n\u001b[0;32m    507\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m returns\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m downside\n",
      "File \u001b[1;32mc:\\Users\\fetom\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:9439\u001b[0m, in \u001b[0;36mNDFrame.resample\u001b[1;34m(self, rule, axis, closed, label, convention, kind, on, level, origin, offset, group_keys)\u001b[0m\n\u001b[0;32m   9436\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   9437\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 9439\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m get_resampler(\n\u001b[0;32m   9440\u001b[0m     cast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries | DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m   9441\u001b[0m     freq\u001b[38;5;241m=\u001b[39mrule,\n\u001b[0;32m   9442\u001b[0m     label\u001b[38;5;241m=\u001b[39mlabel,\n\u001b[0;32m   9443\u001b[0m     closed\u001b[38;5;241m=\u001b[39mclosed,\n\u001b[0;32m   9444\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   9445\u001b[0m     kind\u001b[38;5;241m=\u001b[39mkind,\n\u001b[0;32m   9446\u001b[0m     convention\u001b[38;5;241m=\u001b[39mconvention,\n\u001b[0;32m   9447\u001b[0m     key\u001b[38;5;241m=\u001b[39mon,\n\u001b[0;32m   9448\u001b[0m     level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[0;32m   9449\u001b[0m     origin\u001b[38;5;241m=\u001b[39morigin,\n\u001b[0;32m   9450\u001b[0m     offset\u001b[38;5;241m=\u001b[39moffset,\n\u001b[0;32m   9451\u001b[0m     group_keys\u001b[38;5;241m=\u001b[39mgroup_keys,\n\u001b[0;32m   9452\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\fetom\\anaconda3\\Lib\\site-packages\\pandas\\core\\resample.py:1969\u001b[0m, in \u001b[0;36mget_resampler\u001b[1;34m(obj, kind, **kwds)\u001b[0m\n\u001b[0;32m   1965\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_resampler\u001b[39m(obj: Series \u001b[38;5;241m|\u001b[39m DataFrame, kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Resampler:\n\u001b[0;32m   1966\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1967\u001b[0m \u001b[38;5;124;03m    Create a TimeGrouper and return our resampler.\u001b[39;00m\n\u001b[0;32m   1968\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1969\u001b[0m     tg \u001b[38;5;241m=\u001b[39m TimeGrouper(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m   1970\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tg\u001b[38;5;241m.\u001b[39m_get_resampler(obj, kind\u001b[38;5;241m=\u001b[39mkind)\n",
      "File \u001b[1;32mc:\\Users\\fetom\\anaconda3\\Lib\\site-packages\\pandas\\core\\resample.py:2046\u001b[0m, in \u001b[0;36mTimeGrouper.__init__\u001b[1;34m(self, freq, closed, label, how, axis, fill_method, limit, kind, convention, origin, offset, group_keys, **kwargs)\u001b[0m\n\u001b[0;32m   2043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convention \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124me\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m   2044\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconvention\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for `convention`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2046\u001b[0m freq \u001b[38;5;241m=\u001b[39m to_offset(freq)\n\u001b[0;32m   2048\u001b[0m end_types \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQ\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBM\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBA\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBQ\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m   2049\u001b[0m rule \u001b[38;5;241m=\u001b[39m freq\u001b[38;5;241m.\u001b[39mrule_code\n",
      "File \u001b[1;32moffsets.pyx:4460\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.offsets.to_offset\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32moffsets.pyx:4557\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.offsets.to_offset\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid frequency: ME"
     ]
    }
   ],
   "source": [
    "qs.reports.full(returns['Winners'], returns['Universo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "debd07cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "11\n",
      "63\n"
     ]
    }
   ],
   "source": [
    "teste = []\n",
    "for x in book_winners_defensiva:\n",
    "    if x in book_loosers_defensiva:\n",
    "        teste.append(x)\n",
    "\n",
    "print(len(teste))\n",
    "print(len(book_winners_defensiva))\n",
    "print(len(book_loosers_defensiva))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831e4f31",
   "metadata": {},
   "source": [
    "## OFENSIVA COM LOOP - PRONTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "fa6b313e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CVCB3', 'AMER3', 'TEND3', 'CEAB3']\n",
      "['DIRR3', 'CSMG3', 'POMO4', 'GOAU4', 'STBP3', 'MRFG3', 'NTCO3', 'PSSA3', 'CMIN3', 'CMIG4', 'GGBR4', 'EMBR3', 'RENT3', 'SBSP3', 'SUZB3', 'JBSS3']\n",
      "['CVCB3', 'AMER3', 'TEND3', 'CEAB3', 'DIRR3', 'CSMG3', 'POMO4', 'GOAU4', 'STBP3', 'MRFG3', 'NTCO3', 'PSSA3', 'CMIN3', 'CMIG4', 'GGBR4', 'EMBR3', 'RENT3', 'SBSP3', 'SUZB3', 'JBSS3']\n"
     ]
    }
   ],
   "source": [
    "returns = pd.DataFrame()\n",
    "\n",
    "while True:\n",
    "    rebal = initial_date + pd.DateOffset(months=rebal_time)\n",
    "\n",
    "    # print(f\"Initial: {initial_date}, Rebal: {rebal}, Final: {final_date}\")\n",
    "\n",
    "    if rebal <= final_date:\n",
    "            \n",
    "        ineg_date_analysis = initial_date - pd.DateOffset(months=lookback_ibx)\n",
    "        ineg = dados_ineg[(dados_ineg.index < initial_date) & (dados_ineg.index >= ineg_date_analysis)]\n",
    "        ineg2 = ineg.copy()\n",
    "        ineg = ineg.ffill().bfill()\n",
    "\n",
    "        if not ineg.empty:\n",
    "                ineg = ineg.iloc[[-1]].T.reset_index()\n",
    "                ineg.columns = ['ticker', 'neg']\n",
    "        else:\n",
    "                initial_date += pd.DateOffset(months=rebal_time)\n",
    "                continue    # <<<<<< IMPORTANTE AQUI\n",
    "\n",
    "\n",
    "        #era ticket é o nome da ação e neg é o índice de negociabilidade\n",
    "        ineg.columns = ['ticker','neg'] if 'neg' not in ineg.columns else ineg.columns\n",
    "\n",
    "\n",
    "        #no fim essa lista iá significar que as ações investidas estão na lista de boa negociabilidade\n",
    "        ibx_tickers = ineg.sort_values(by='neg', ascending=False).head(100)['ticker'].tolist()\n",
    "\n",
    "    # --------------------------------------------------------------\n",
    "\n",
    "        # OFENSIVA\n",
    "\n",
    "        #momentum:\n",
    "        # Define o intervalo para analisar o desempenho passado das ações\n",
    "        momentum_date_analysis = initial_date - pd.DateOffset(months=lookback_momentum)\n",
    "        # Filtra os preços dentro do intervalo desejado\n",
    "        # print(closing_price)\n",
    "        momentum = closing_price[(closing_price.index < initial_date) & (closing_price.index > momentum_date_analysis)]\n",
    "        # print(momentum)\n",
    "\n",
    "        #cálculo do momentum:\n",
    "        momentum = momentum.pct_change().add(1).cumprod().add(-1)\n",
    "        # Pega apenas a última linha dos retornos acumulados (mais recente)\n",
    "        momentum = momentum.iloc[-1]\n",
    "        # Converte para DataFrame e renomeia as colunas\n",
    "        momentum = momentum.reset_index()\n",
    "        momentum.columns = ['ticker', 'momentum'] #Ticker = nome da ação e value = valor da ação\n",
    "        # print(ibx_tickers)\n",
    "        momentum = momentum[momentum['ticker'].isin(ibx_tickers)]  #Verifica se a ação está entre as top 100 mais negociadas na bolsa \n",
    "\n",
    "        # Ordena da maior performance para a menor\n",
    "        momentum = momentum.sort_values(by='momentum', ascending=False).reset_index(drop=True)\n",
    "        # print(momentum)\n",
    "\n",
    "        # low size em cima de momentum\n",
    "\n",
    "        momentum_20_pc = momentum['momentum'].quantile(0.80) \n",
    "        momentum_20_pc = momentum[momentum['momentum'] >= momentum_20_pc]\n",
    "\n",
    "        acoes_20_momentum = momentum_20_pc['ticker'].tolist()\n",
    "\n",
    "        low_size_date_analysis = initial_date - pd.DateOffset(months=lookback_low_size)\n",
    "        low_size_filtro = low_size[(low_size.index < initial_date) & (low_size.index > low_size_date_analysis)]\n",
    "\n",
    "        if low_size_filtro.empty:\n",
    "            # print(\"Sem dados de low_size para:\", initial_date)\n",
    "            initial_date += pd.DateOffset(months=rebal_time)\n",
    "            continue\n",
    "\n",
    "\n",
    "        low_size_filtro = low_size_filtro.iloc[-1]\n",
    "        low_size_filtro=low_size_filtro.reset_index()\n",
    "        low_size_filtro.columns = ['ticker','low_size']\n",
    "\n",
    "        \n",
    "        low_size_novo = low_size_filtro[low_size_filtro['ticker'].isin(acoes_20_momentum)]\n",
    "        low_size_novo = low_size_novo.sort_values(by='low_size', ascending=True).reset_index(drop=True)\n",
    "\n",
    "        lista_low_size = low_size_novo.ticker.tolist()\n",
    "        \n",
    "        # analisar se faz sentido essa constatação de winners e loosers ou se é ao contrário\n",
    "\n",
    "        limite_winners = low_size_novo.low_size.quantile(0.20)\n",
    "\n",
    "        book_loosers_ofensiva = low_size_novo[low_size_novo['low_size'] > limite_winners]\n",
    "        book_loosers_ofensiva = book_loosers_ofensiva.ticker.tolist()\n",
    "\n",
    "        book_winners_ofensiva = low_size_novo[low_size_novo['low_size'] <= limite_winners]   \n",
    "        book_winners_ofensiva = book_winners_ofensiva.ticker.tolist()\n",
    "\n",
    "\n",
    "        initial_date = initial_date + pd.DateOffset(months=rebal_time)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "print(book_winners_ofensiva)\n",
    "print(book_loosers_ofensiva)\n",
    "print(lista_low_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b54e46",
   "metadata": {},
   "source": [
    "## DEFENSIVA COM LOOP - TESTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "377157e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "returns = pd.DataFrame()\n",
    "\n",
    "quality_original = quality.copy()\n",
    "value_original = value.copy()\n",
    "\n",
    "# print(f\"Initial: {initial_date}, Rebal: {rebal}, Final: {final_date}\")\n",
    "while True:\n",
    "        \n",
    "        rebal = initial_date + pd.DateOffset(months=rebal_time)\n",
    "        \n",
    "        if rebal <= final_date:\n",
    "        \n",
    "                ineg_date_analysis = initial_date - pd.DateOffset(months=lookback_ibx)\n",
    "                ineg = dados_ineg[(dados_ineg.index < initial_date) & (dados_ineg.index >= ineg_date_analysis)]\n",
    "                ineg2 = ineg.copy()\n",
    "                ineg = ineg.ffill().bfill()\n",
    "\n",
    "                if not ineg.empty:\n",
    "                        ineg = ineg.iloc[[-1]].T.reset_index()\n",
    "                        ineg.columns = ['ticker', 'neg']\n",
    "                else:\n",
    "                        initial_date += pd.DateOffset(months=rebal_time)\n",
    "                        continue  # <<<<<< IMPORTANTE AQUI\n",
    "\n",
    "                # print(ineg.shape)\n",
    "                # print(ineg.columns)\n",
    "\n",
    "        # era ticket é o nome da ação e neg é o índice de negociabilidade\n",
    "        # NÃO precisa mais mudar de novo o nome das colunas aqui\n",
    "        # (já renomeamos antes)\n",
    "\n",
    "\n",
    "\n",
    "                #era ticket é o nome da ação e neg é o índice de negociabilidade\n",
    "                ineg.columns = ['ticker','neg'] if 'neg' not in ineg.columns else ineg.columns\n",
    "                \n",
    "                #no fim essa lista iá significar que as ações investidas estão na lista de boa negociabilidade\n",
    "                ibx_tickers = ineg.sort_values(by='neg', ascending=False).head(100)['ticker'].tolist()\n",
    "                        \n",
    "                # --------------------------------------------------------------\n",
    "                low_vol_date_analysis = initial_date - pd.DateOffset(months=lookback_low_vol)\n",
    "                low_vol_prices = closing_price[(closing_price.index < initial_date) & (closing_price.index > low_vol_date_analysis)]\n",
    "\n",
    "                # Calcula volatilidade (desvio padrão dos retornos)\n",
    "                low_vol = low_vol_prices.pct_change().std()  \n",
    "                low_vol = low_vol.reset_index()\n",
    "                low_vol.columns = ['ticker', 'low_vol']\n",
    "\n",
    "                # Filtra para tickers do IBX\n",
    "                low_vol = low_vol[low_vol['ticker'].isin(ibx_tickers)]\n",
    "                low_vol = low_vol.sort_values(by='low_vol', ascending=True).reset_index(drop=True)\n",
    "\n",
    "                low_vol_score = low_vol.copy()\n",
    "                low_vol_score['score'] = low_vol.index + 1\n",
    "                \n",
    "                lista_low_vol = low_vol.ticker.tolist()\n",
    "\n",
    "\n",
    "                # quality\n",
    "                # quality\n",
    "                # print(type(quality.index))\n",
    "                # print(type(initial_date))\n",
    "                quality_date_analysis = initial_date - pd.DateOffset(months=lookback_quality)\n",
    "                quality = quality_original[(quality_original.index < initial_date) & (quality_original.index > quality_date_analysis)]\n",
    "\n",
    "                if not quality.empty:\n",
    "                        quality = quality.iloc[[-1]].T.reset_index()\n",
    "                        quality.columns = ['ticker','quality']\n",
    "                else:\n",
    "                        initial_date += pd.DateOffset(months=rebal_time)\n",
    "                        continue\n",
    "\n",
    "                # quality_date_analysis = initial_date - pd.DateOffset(months=lookback_quality)\n",
    "                # quality = quality[(quality.index < initial_date) & (quality.index > quality_date_analysis)]\n",
    "                # quality = quality.iloc[-1]\n",
    "                # quality = quality.reset_index()\n",
    "                # quality.columns = ['ticker','quality']\n",
    "                quality = quality[quality['ticker'].isin(lista_low_vol)]\n",
    "                quality = quality.sort_values(by='quality', ascending=False).reset_index(drop=True)\n",
    "\n",
    "                quality_score = quality.copy()\n",
    "                quality_score['score'] = quality.index + 1\n",
    "\n",
    "                quality_score['score_result'] = quality_score['score'] + low_vol_score['score']\n",
    "                quality_score = quality_score.sort_values(by='score_result', ascending=True).reset_index(drop=True)\n",
    "                lista_quality = quality.ticker.tolist()\n",
    "\n",
    "\n",
    "                acoes_25_quality_low_vol = quality_score.score_result.quantile(0.75)\n",
    "                acoes_25_quality_low_vol = quality_score[quality_score['score_result'] <= acoes_25_quality_low_vol]   \n",
    "                acoes_25_quality_low_vol = acoes_25_quality_low_vol.ticker.tolist()\n",
    "\n",
    "\n",
    "                # value\n",
    "\n",
    "                value_date_analysis = initial_date - pd.DateOffset(months=lookback_value)\n",
    "                value = value_original[(value_original.index < initial_date) & (value_original.index > value_date_analysis)]\n",
    "                value = value.iloc[-1]\n",
    "                value = value.reset_index()\n",
    "                value.columns = ['ticker','value']\n",
    "                value = value[value['ticker'].isin(acoes_25_quality_low_vol)]\n",
    "                value = value.sort_values(by='value', ascending=False).reset_index(drop=True)\n",
    "\n",
    "\n",
    "                limite_winners = value.value.quantile(0.85)\n",
    "\n",
    "                book_winners_defensiva = value[value['value'] >= limite_winners]   \n",
    "                book_winners_defensiva = book_winners_defensiva.ticker.tolist()\n",
    "\n",
    "                book_loosers_defensiva = value[value['value'] < limite_winners]\n",
    "                book_loosers_defensiva = book_loosers_defensiva.ticker.tolist()\n",
    "\n",
    "                initial_date = initial_date + pd.DateOffset(months=rebal_time)\n",
    "        else:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f075799c",
   "metadata": {},
   "source": [
    "## Ponderação de Ofensiva e Defensiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b635619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------\n",
    "\n",
    "# Backtest defensiva - winners\n",
    "backtest_defensiva_w = closing_price[(closing_price.index >= initial_date) & (closing_price.index < rebal)]\n",
    "backtest_defensiva_w = backtest_defensiva_w[book_winners_defensiva].pct_change().replace(np.nan,0)\n",
    "backtest_defensiva_w['Retorno'] = backtest_defensiva_w.mean(axis=1)\n",
    "backtest_defensiva_w_ret = backtest_defensiva_w['Retorno'][1:]\n",
    "\n",
    "# Backtest ofensiva - winners\n",
    "backtest_ofensiva_w = closing_price[(closing_price.index >= initial_date) & (closing_price.index < rebal)]\n",
    "backtest_ofensiva_w = backtest_ofensiva_w[book_winners_ofensiva].pct_change().replace(np.nan,0)\n",
    "backtest_ofensiva_w['Retorno'] = backtest_ofensiva_w.mean(axis=1)\n",
    "backtest_ofensiva_w_ret = backtest_ofensiva_w['Retorno'][1:]\n",
    "\n",
    "# Combina os dois backtests: 80% defensiva + 20% ofensiva\n",
    "backtest_winners_ret = 0.8 * backtest_defensiva_w_ret + 0.2 * backtest_ofensiva_w_ret\n",
    "\n",
    "#---------------------------------------------------------------\n",
    "\n",
    "# Backtest defensiva - loosers\n",
    "backtest_defensiva_l = closing_price[(closing_price.index >= initial_date) & (closing_price.index < rebal)]\n",
    "backtest_defensiva_l = backtest_defensiva_l[book_loosers_defensiva].pct_change().replace(np.nan,0)\n",
    "backtest_defensiva_l['Retorno'] = backtest_defensiva_l.mean(axis=1)\n",
    "backtest_defensiva_l_ret = backtest_defensiva_l['Retorno'][1:]\n",
    "\n",
    "# Backtest ofensiva - loosers\n",
    "backtest_ofensiva_l = closing_price[(closing_price.index >= initial_date) & (closing_price.index < rebal)]\n",
    "backtest_ofensiva_l = backtest_ofensiva_l[book_loosers_ofensiva].pct_change().replace(np.nan,0)\n",
    "backtest_ofensiva_l['Retorno'] = backtest_ofensiva_l.mean(axis=1)\n",
    "backtest_ofensiva_l_ret = backtest_ofensiva_l['Retorno'][1:]\n",
    "\n",
    "# Combina os dois backtests: 80% defensiva + 20% ofensiva\n",
    "backtest_loosers_ret = 0.8 * backtest_defensiva_l_ret + 0.2 * backtest_ofensiva_l_ret\n",
    "\n",
    "# Universo (opcional: você pode manter o universo como todos os tickers do IBX)\n",
    "backtest_universe = closing_price[(closing_price.index >= initial_date) & (closing_price.index < rebal)]\n",
    "backtest_universe = backtest_universe[ibx_tickers].pct_change().replace(np.nan,0)\n",
    "backtest_universe['Retorno'] = backtest_universe.mean(axis=1)\n",
    "backtest_universe_ret = backtest_universe['Retorno'][1:]\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "# retorno\n",
    "retorno_rebal = pd.DataFrame({\n",
    "    'Winners': backtest_winners_ret,\n",
    "    'Universo': backtest_universe_ret,\n",
    "    'Losers': backtest_loosers_ret,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d9127ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho losers defensiva: 80\n",
      "Tamanho winners defensiva: 9\n",
      "Tamanho losers ofensiva: 9\n",
      "Tamanho winners defensiva: 1\n"
     ]
    }
   ],
   "source": [
    "print('Tamanho losers defensiva:', len(book_loosers_defensiva))\n",
    "print('Tamanho winners defensiva:', len(book_winners_defensiva))\n",
    "print('Tamanho losers ofensiva:', len(book_loosers_ofensiva))\n",
    "print('Tamanho winners defensiva:', len(book_winners_ofensiva))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
