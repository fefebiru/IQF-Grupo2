{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f5b26bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import warnings\n",
    "# import quantstats as qs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd256f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "closing_price1 = pd.read_excel('fechamento_limpo.xlsx')\n",
    "print('1')\n",
    "quality1 = pd.read_excel('base_quality_limpa.xlsx')\n",
    "print('1')\n",
    "low_size1 = pd.read_excel('base_low_size_limpa.xlsx')\n",
    "print('1')\n",
    "value1 = pd.read_excel('value_limpo.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8d9fa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_size1[\"Data\"] = pd.to_datetime(low_size1[\"Data\"])\n",
    "low_size1 = low_size1.set_index(\"Data\")\n",
    "\n",
    "quality1[\"Data\"] = pd.to_datetime(quality1[\"Data\"])\n",
    "quality1 = quality1.set_index(\"Data\")\n",
    "\n",
    "value1[\"Data\"] = pd.to_datetime(value1[\"Data\"])\n",
    "value1 = value1.set_index(\"Data\")\n",
    "\n",
    "closing_price1[\"Data\"] = pd.to_datetime(closing_price1[\"Data\"])\n",
    "closing_price1 = closing_price1.set_index(\"Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fe3d04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_ineg1 = pd.read_excel('ineg_limpo (3).xlsx')\n",
    "dados_ineg1['Data'] = pd.to_datetime(dados_ineg1['Data'])\n",
    "dados_ineg1 = dados_ineg1.set_index('Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa02add0",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_date = pd.Timestamp(dt.datetime(2000,1,24))\n",
    "final_date =pd.Timestamp(dt.datetime(2024,12,31))\n",
    "\n",
    "\n",
    "low_size2 = low_size1[(low_size1.index >= initial_date) & (low_size1.index <=final_date)]\n",
    "closing_price2 = closing_price1[(closing_price1.index >= initial_date) & (closing_price1.index <=final_date)]\n",
    "quality2 = quality1[(quality1.index >= initial_date) & (quality1.index <=final_date)]\n",
    "value2 = value1[(value1.index >= initial_date) & (value1.index <=final_date)]\n",
    "dados_ineg2 = dados_ineg1[(dados_ineg1.index >= initial_date) & (dados_ineg1.index <=final_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7aff01eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Força o índice para datetime corretamente\n",
    "closing_price = closing_price1.copy()\n",
    "closing_price.index = pd.to_datetime(closing_price.index, errors='coerce')\n",
    "closing_price = closing_price[closing_price.index.notna()]  # remove datas inválidas\n",
    "\n",
    "\n",
    "low_size = low_size1.copy()\n",
    "low_size.index = pd.to_datetime(low_size.index, errors='coerce')\n",
    "low_size = low_size[low_size.index.notna()]\n",
    "\n",
    "\n",
    "quality = quality1.copy()\n",
    "quality.index = pd.to_datetime(quality.index, errors='coerce')\n",
    "quality = quality[quality.index.notna()]\n",
    "\n",
    "\n",
    "value = value1.copy()\n",
    "value.index = pd.to_datetime(value.index, errors='coerce')\n",
    "value = value[value.index.notna()]\n",
    "# Colocar os lookcbacks de cada estrategia\n",
    "dados_ineg = dados_ineg1.copy()\n",
    "\n",
    "\n",
    "lookback_momentum = 3  #  3 mes\n",
    "lookback_low_size = 3  #  3 mes\n",
    "lookback_low_vol = 3 #  3 mes\n",
    "lookback_quality = 3  #  3 mes\n",
    "lookback_value = 3  #  3 mes\n",
    "lookback_ibx = 3  #  3 mes\n",
    "\n",
    "rebal_time = 1  #  1 mes --> unico para toda a carteira\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89597224",
   "metadata": {},
   "outputs": [],
   "source": [
    "closing_price = closing_price2.copy()\n",
    "value = value2.copy()\n",
    "low_size = low_size2.copy() \n",
    "quality = quality2.copy()\n",
    "dados_ineg = dados_ineg2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d60af70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_ineg = dados_ineg.dropna(axis=1, how='all')\n",
    "\n",
    "cutoff_date = initial_date\n",
    "dados_ineg = dados_ineg[dados_ineg.index >= cutoff_date]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831e4f31",
   "metadata": {},
   "source": [
    "## OFENSIVA SEM LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa6b313e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LIPR3', 'PNVL3', 'BDLL4', 'POMO4', 'POMO3', 'EMAE4', 'UNIP3', 'BEES3', 'ISAE3', 'ISAE4', 'CGAS5', 'TIMS3', 'OIBR3', 'EMBR3', 'VIVT3', 'PETR3']\n"
     ]
    }
   ],
   "source": [
    "returns = pd.DataFrame()\n",
    "\n",
    "\n",
    "rebal = initial_date + pd.DateOffset(months=rebal_time)\n",
    "\n",
    "# print(f\"Initial: {initial_date}, Rebal: {rebal}, Final: {final_date}\")\n",
    "\n",
    "if rebal <= final_date:\n",
    "        \n",
    "    ineg_date_analysis = initial_date - pd.DateOffset(months=lookback_ibx)\n",
    "    ineg = dados_ineg[(dados_ineg.index < initial_date) & (dados_ineg.index >= ineg_date_analysis)]\n",
    "    ineg = ineg.bfill().ffill()\n",
    "\n",
    "    if not ineg.empty:\n",
    "        ineg = ineg.iloc[-1]\n",
    "    else:\n",
    "        initial_date += pd.DateOffset(months=rebal_time)\n",
    "\n",
    "\n",
    "    ineg = ineg.reset_index()\n",
    "    # print(ineg)\n",
    "\n",
    "\n",
    "    #era ticket é o nome da ação e neg é o índice de negociabilidade\n",
    "    ineg.columns = ['ticker','neg'] if 'neg' not in ineg.columns else ineg.columns\n",
    "    \n",
    "    #no fim essa lista iá significar que as ações investidas estão na lista de boa negociabilidade\n",
    "    ibx_tickers = ineg.sort_values(by='neg', ascending=False).head(100)['ticker'].tolist()\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "    # OFENSIVA\n",
    "\n",
    "    #momentum:\n",
    "    # Define o intervalo para analisar o desempenho passado das ações\n",
    "    momentum_date_analysis = initial_date - pd.DateOffset(months=lookback_momentum)\n",
    "    # Filtra os preços dentro do intervalo desejado\n",
    "    # print(closing_price)\n",
    "    momentum = closing_price[(closing_price.index < initial_date) & (closing_price.index > momentum_date_analysis)]\n",
    "    # print(momentum)\n",
    "\n",
    "    #cálculo do momentum:\n",
    "    momentum = momentum.pct_change().add(1).cumprod().add(-1)\n",
    "    # Pega apenas a última linha dos retornos acumulados (mais recente)\n",
    "    momentum = momentum.iloc[-1]\n",
    "    # Converte para DataFrame e renomeia as colunas\n",
    "    momentum = momentum.reset_index()\n",
    "    momentum.columns = ['ticker', 'momentum'] #Ticker = nome da ação e value = valor da ação\n",
    "    # print(ibx_tickers)\n",
    "    momentum = momentum[momentum['ticker'].isin(ibx_tickers)]  #Verifica se a ação está entre as top 100 mais negociadas na bolsa \n",
    "\n",
    "    # Ordena da maior performance para a menor\n",
    "    momentum = momentum.sort_values(by='momentum', ascending=False).reset_index(drop=True)\n",
    "    # print(momentum)\n",
    "\n",
    "    # low size em cima de momentum\n",
    "\n",
    "    momentum_20_pc = momentum['momentum'].quantile(0.80) \n",
    "    momentum_20_pc = momentum[momentum['momentum'] >= momentum_20_pc]\n",
    "\n",
    "    acoes_20_momentum = momentum_20_pc['ticker'].tolist()\n",
    "\n",
    "    low_size_date_analysis = initial_date - pd.DateOffset(months=lookback_low_size)\n",
    "    low_size_filtro = low_size[(low_size.index < initial_date) & (low_size.index > low_size_date_analysis)]\n",
    "\n",
    "    if low_size_filtro.empty:\n",
    "        # print(\"Sem dados de low_size para:\", initial_date)\n",
    "        initial_date += pd.DateOffset(months=rebal_time)\n",
    "\n",
    "\n",
    "    low_size_filtro = low_size_filtro.iloc[-1]\n",
    "    low_size_filtro=low_size_filtro.reset_index()\n",
    "    low_size_filtro.columns = ['ticker','low_size']\n",
    "\n",
    "    \n",
    "    low_size_novo = low_size_filtro[low_size_filtro['ticker'].isin(acoes_20_momentum)]\n",
    "    low_size_novo = low_size_novo.sort_values(by='low_size', ascending=True).reset_index(drop=True)\n",
    "\n",
    "    lista_low_size = low_size_novo.ticker.tolist()\n",
    "    \n",
    "\n",
    "\n",
    "    book_winners_ofensiva = low_size_novo.low_size.quantile(0.80)\n",
    "    book_winners_ofensiva = low_size_novo[low_size_novo['low_size'] <= book_winners_ofensiva]   \n",
    "    book_winners_ofensiva = book_winners_ofensiva.ticker.tolist()\n",
    "    book_loosers_ofensiva = low_size_novo.low_size.quantile(0.20)\n",
    "    book_loosers_ofensiva = low_size_novo[low_size_novo['low_size'] >= book_loosers_ofensiva]\n",
    "    book_loosers_ofensiva = book_loosers_ofensiva.ticker.tolist()\n",
    "\n",
    "    print(book_loosers_ofensiva)\n",
    "    \n",
    "\n",
    "\n",
    "    initial_date = initial_date + pd.DateOffset(months=rebal_time)\n",
    "\n",
    "\n",
    "# print(rebal)\n",
    "# print(final_date)\n",
    "# print(initial_date)\n",
    "# print(count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4b8f91",
   "metadata": {},
   "source": [
    "## DEFENSIVA SEM LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377157e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "returns = pd.DataFrame()\n",
    "\n",
    "\n",
    "rebal = initial_date + pd.DateOffset(months=rebal_time)\n",
    "\n",
    "# print(f\"Initial: {initial_date}, Rebal: {rebal}, Final: {final_date}\")\n",
    "\n",
    "if rebal <= final_date:\n",
    "        \n",
    "        ineg_date_analysis = initial_date - pd.DateOffset(months=lookback_ibx)\n",
    "        ineg = dados_ineg[(dados_ineg.index < initial_date) & (dados_ineg.index >= ineg_date_analysis)]\n",
    "        ineg = ineg.bfill().ffill()\n",
    "\n",
    "        if not ineg.empty:\n",
    "                ineg = ineg.iloc[-1]\n",
    "        else:\n",
    "                initial_date += pd.DateOffset(months=rebal_time)\n",
    "\n",
    "\n",
    "        ineg = ineg.reset_index()\n",
    "        # print(ineg)\n",
    "\n",
    "\n",
    "        #era ticket é o nome da ação e neg é o índice de negociabilidade\n",
    "        ineg.columns = ['ticker','neg'] if 'neg' not in ineg.columns else ineg.columns\n",
    "        \n",
    "        #no fim essa lista iá significar que as ações investidas estão na lista de boa negociabilidade\n",
    "        ibx_tickers = ineg.sort_values(by='neg', ascending=False).head(100)['ticker'].tolist()\n",
    "                \n",
    "        # --------------------------------------------------------------\n",
    "        low_vol_date_analysis = initial_date - pd.DateOffset(months=lookback_low_vol)\n",
    "        low_vol_prices = closing_price[(closing_price.index < initial_date) & (closing_price.index > low_vol_date_analysis)]\n",
    "\n",
    "        # Calcula volatilidade (desvio padrão dos retornos)\n",
    "        low_vol = low_vol_prices.pct_change().std()  \n",
    "        low_vol = low_vol.reset_index()\n",
    "        low_vol.columns = ['ticker', 'low_vol']\n",
    "\n",
    "        # Filtra para tickers do IBX\n",
    "        low_vol = low_vol[low_vol['ticker'].isin(ibx_tickers)]\n",
    "        low_vol = low_vol.sort_values(by='low_vol', ascending=True).reset_index(drop=True)\n",
    "\n",
    "        low_vol_score = low_vol.copy()\n",
    "        low_vol_score['score'] = low_vol.index + 1\n",
    "        \n",
    "        lista_low_vol = low_vol.ticker.tolist()\n",
    "\n",
    "\n",
    "        # quality\n",
    "        quality_date_analysis = initial_date - pd.DateOffset(months=lookback_quality)\n",
    "        quality = quality[(quality.index < initial_date) & (quality.index > quality_date_analysis)]\n",
    "        quality = quality.iloc[-1]\n",
    "        quality = quality.reset_index()\n",
    "        quality.columns = ['ticker','quality']\n",
    "        quality = quality[quality['ticker'].isin(lista_low_vol)]\n",
    "        quality = quality.sort_values(by='quality', ascending=False).reset_index(drop=True)\n",
    "\n",
    "        quality_score = quality.copy()\n",
    "        quality_score['score'] = quality.index + 1\n",
    "\n",
    "        quality_score['score_result'] = quality_score['score'] + low_vol_score['score']\n",
    "        quality_score = quality_score.sort_values(by='score_result', ascending=True).reset_index(drop=True)\n",
    "        lista_quality = quality.ticker.tolist()\n",
    "\n",
    "\n",
    "        acoes_25_quality_low_vol = quality_score.score_result.quantile(0.75)\n",
    "        acoes_25_quality_low_vol = quality_score[quality_score['score_result'] <= acoes_25_quality_low_vol]   \n",
    "        acoes_25_quality_low_vol = acoes_25_quality_low_vol.ticker.tolist()\n",
    "\n",
    "\n",
    "        # value\n",
    "\n",
    "        value_date_analysis = initial_date - pd.DateOffset(months=lookback_value)\n",
    "        value = value[(value.index < initial_date) & (value.index > value_date_analysis)]\n",
    "        value = value.iloc[-1]\n",
    "        value = value.reset_index()\n",
    "        value.columns = ['ticker','value']\n",
    "        value = value[value['ticker'].isin(acoes_25_quality_low_vol)]\n",
    "        value = value.sort_values(by='value', ascending=False).reset_index(drop=True)\n",
    "\n",
    "\n",
    "        book_winners_defensiva = value.value.quantile(0.85)\n",
    "        book_winners_defensiva = value[value['value'] <= book_winners_defensiva]   \n",
    "        book_winners_defensiva = book_winners_defensiva.ticker.tolist()\n",
    "        book_loosers_defensiva = value.value.quantile(0.15)\n",
    "        book_loosers_defensiva = value[value['value'] >= book_loosers_defensiva]\n",
    "        book_loosers_defensiva = book_loosers_defensiva.ticker.tolist()\n",
    "\n",
    "        initial_date = initial_date + pd.DateOffset(months=rebal_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d045db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = pd.DataFrame()\n",
    "count = 0\n",
    "while True:\n",
    "    count+=1\n",
    "\n",
    "    rebal = initial_date + pd.DateOffset(months=rebal_time)\n",
    "    \n",
    "    # print(f\"Initial: {initial_date}, Rebal: {rebal}, Final: {final_date}\")\n",
    "\n",
    "    if rebal <= final_date:\n",
    "         \n",
    "        ineg_date_analysis = initial_date - pd.DateOffset(months=lookback_ibx)\n",
    "        ineg = dados_ineg[(dados_ineg.index < initial_date) & (dados_ineg.index >= ineg_date_analysis)]\n",
    "        ineg = ineg.bfill().ffill()\n",
    "\n",
    "        if not ineg.empty:\n",
    "            ineg = ineg.iloc[-1]\n",
    "        else:\n",
    "            initial_date += pd.DateOffset(months=rebal_time)\n",
    "            continue\n",
    "\n",
    "        ineg = ineg.reset_index()\n",
    "\n",
    "        #era ticket é o nome da ação e neg é o índice de negociabilidade\n",
    "        ineg.columns = ['ticker','neg'] if 'neg' not in ineg.columns else ineg.columns\n",
    "\n",
    "        #no fim essa lista iá significar que as ações investidas estão na lista de boa negociabilidade\n",
    "        ibx_tickers = ineg.sort_values(by='neg', ascending=False).head(100)['ticker'].tolist()\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "        # OFENSIVA\n",
    "\n",
    "        #momentum:\n",
    "        # Define o intervalo para analisar o desempenho passado das ações\n",
    "        momentum_date_analysis = initial_date - pd.DateOffset(months=lookback_momentum)\n",
    "        # Filtra os preços dentro do intervalo desejado\n",
    "        momentum = closing_price[(closing_price.index < initial_date) & (closing_price.index > momentum_date_analysis)]\n",
    "        \n",
    "\n",
    "        #cálculo do momentum:\n",
    "        momentum = momentum.pct_change().add(1).cumprod().add(-1)\n",
    "        # Pega apenas a última linha dos retornos acumulados (mais recente)\n",
    "        momentum = momentum.iloc[-1]\n",
    "        # Converte para DataFrame e renomeia as colunas\n",
    "        momentum = momentum.reset_index()\n",
    "        momentum.columns = ['ticker', 'momentum'] #Ticker = nome da ação e value = valor da ação\n",
    "        momentum = momentum[momentum['ticker'].isin(ibx_tickers)]  #Verifica se a ação está entre as top 100 mais negociadas na bolsa \n",
    "\n",
    "        # Ordena da maior performance para a menor\n",
    "        momentum = momentum.sort_values(by='momentum', ascending=False).reset_index(drop=True)\n",
    "\n",
    "        # low size em cima de momentum\n",
    "\n",
    "        momentum_20_pc = momentum['momentum'].quantile(0.80) \n",
    "        momentum_20_pc = momentum[momentum['momentum'] >= momentum_20_pc]\n",
    "\n",
    "        acoes_20_momentum = momentum_20_pc['ticker'].tolist()\n",
    "\n",
    "        low_size_date_analysis = initial_date - pd.DateOffset(months=lookback_low_size)\n",
    "        low_size_filtro = low_size[(low_size.index < initial_date) & (low_size.index > low_size_date_analysis)]\n",
    "\n",
    "        if low_size_filtro.empty:\n",
    "            print(\"Sem dados de low_size para:\", initial_date)\n",
    "            initial_date += pd.DateOffset(months=rebal_time)\n",
    "            continue\n",
    "\n",
    "        low_size_filtro = low_size_filtro.iloc[-1]\n",
    "        low_size_filtro=low_size_filtro.reset_index()\n",
    "        low_size_filtro.columns = ['ticker','low_size']\n",
    "\n",
    "        \n",
    "        low_size_novo = low_size_filtro[low_size_filtro['ticker'].isin(acoes_20_momentum)]\n",
    "        low_size_novo = low_size_novo.sort_values(by='low_size', ascending=True).reset_index(drop=True)\n",
    "\n",
    "        lista_low_size = low_size_novo.ticker.tolist()\n",
    "        \n",
    "\n",
    "\n",
    "        book_winners_ofensiva = low_size_novo.ticker.quantile(0.80)\n",
    "        book_winners_ofensiva = low_size_novo[low_size_novo['low_size'] <= book_winners_ofensiva]\n",
    "        book_loosers_ofensiva = low_size_novo.ticker.quantile(0.20)\n",
    "        book_loosers_ofensiva = low_size_novo[low_size_novo['low_size'] >= book_loosers_ofensiva]\n",
    "\n",
    "\n",
    "        initial_date = initial_date + pd.DateOffset(months=rebal_time)\n",
    "\n",
    "    else:\n",
    "        break\n",
    "# print(rebal)\n",
    "# print(final_date)\n",
    "# print(initial_date)\n",
    "# print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258fdad3",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16920\\1617406138.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[0mquality_date_analysis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minitial_date\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDateOffset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonths\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlookback_quality\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0mquality\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquality\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquality\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0minitial_date\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mquality\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mquality_date_analysis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[0mquality\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquality\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[0mquality\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquality\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[0mquality\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'ticker'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'quality'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lafer\\IQF\\IQF-Grupo2\\venv\\Lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1189\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_deprecated_callable_usage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaybe_callable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1191\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lafer\\IQF\\IQF-Grupo2\\venv\\Lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1750\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1751\u001b[0m             \u001b[1;31m# validate the location\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1752\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1753\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1754\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lafer\\IQF\\IQF-Grupo2\\venv\\Lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1683\u001b[0m         \u001b[0mlen_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1684\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1685\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1687\u001b[0m     \u001b[1;31m# -------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "returns = pd.DataFrame()\n",
    "\n",
    "while True:\n",
    "\n",
    "    rebal = initial_date + pd.DateOffset(months=rebal_time)\n",
    "    \n",
    "    # print(f\"Initial: {initial_date}, Rebal: {rebal}, Final: {final_date}\")\n",
    "\n",
    "    if rebal <= final_date:\n",
    "         \n",
    "        ineg_date_analysis = initial_date - pd.DateOffset(months=lookback_ibx)\n",
    "        ineg = dados_ineg[(dados_ineg.index < initial_date) & (dados_ineg.index >= ineg_date_analysis)]\n",
    "        ineg = ineg.bfill().ffill()\n",
    "\n",
    "        if not ineg.empty:\n",
    "            ineg = ineg.iloc[-1]\n",
    "        else:\n",
    "            initial_date += pd.DateOffset(months=rebal_time)\n",
    "            continue\n",
    "\n",
    "        ineg = ineg.reset_index()\n",
    "\n",
    "        #era ticket é o nome da ação e neg é o índice de negociabilidade\n",
    "        ineg.columns = ['ticker','neg'] if 'neg' not in ineg.columns else ineg.columns\n",
    "\n",
    "        #no fim essa lista iá significar que as ações investidas estão na lista de boa negociabilidade\n",
    "        ibx_tickers = ineg.sort_values(by='neg', ascending=False).head(100)['ticker'].tolist()\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "        # OFENSIVA\n",
    "\n",
    "        #momentum:\n",
    "        # Define o intervalo para analisar o desempenho passado das ações\n",
    "        momentum_date_analysis = initial_date - pd.DateOffset(months=lookback_momentum)\n",
    "        # Filtra os preços dentro do intervalo desejado\n",
    "        momentum = closing_price[(closing_price.index < initial_date) & (closing_price.index > momentum_date_analysis)]\n",
    "        #cálculo do momentum:\n",
    "        momentum = momentum.pct_change().add(1).cumprod().add(-1)\n",
    "        # Pega apenas a última linha dos retornos acumulados (mais recente)\n",
    "        momentum = momentum.iloc[-1]\n",
    "        # Converte para DataFrame e renomeia as colunas\n",
    "        momentum = momentum.reset_index()\n",
    "        momentum.columns = ['ticker', 'momentum'] #Ticker = nome da ação e value = valor da ação\n",
    "        momentum = momentum[momentum['ticker'].isin(ibx_tickers)]  #Verifica se a ação está entre as top 100 mais negociadas na bolsa \n",
    "\n",
    "        # Ordena da maior performance para a menor\n",
    "        momentum = momentum.sort_values(by='momentum', ascending=False).reset_index(drop=True)\n",
    "\n",
    "\n",
    "        # low size em cima de momentum\n",
    "\n",
    "        momentum_20_pc = momentum['momentum'].quantile(0.80) \n",
    "        momentum_20_pc = momentum[momentum['momentum'] >= momentum_20_pc]\n",
    "\n",
    "        acoes_20_momentum = momentum_20_pc['ticker'].tolist()\n",
    "\n",
    "        low_size_date_analysis = initial_date - pd.DateOffset(months=lookback_low_size)\n",
    "        low_size_filtro = low_size[(low_size.index < initial_date) & (low_size.index > low_size_date_analysis)]\n",
    "\n",
    "        if low_size_filtro.empty:\n",
    "            print(\"Sem dados de low_size para:\", initial_date)\n",
    "            initial_date += pd.DateOffset(months=rebal_time)\n",
    "            continue\n",
    "\n",
    "        low_size_filtro = low_size_filtro.iloc[-1]\n",
    "        low_size_filtro=low_size_filtro.reset_index()\n",
    "        low_size_filtro.columns = ['ticker','low_size']\n",
    "\n",
    "        \n",
    "        low_size_novo = low_size_filtro[low_size_filtro['ticker'].isin(acoes_20_momentum)]\n",
    "        low_size_novo = low_size_novo.sort_values(by='low_size', ascending=True).reset_index(drop=True)\n",
    "\n",
    "        lista_low_size = low_size_novo.ticker.tolist()\n",
    "        \n",
    "\n",
    "\n",
    "        book_winners_ofensiva = low_size_novo.ticker.quantile(0.80)\n",
    "        book_winners_ofensiva = low_size_novo[low_size_novo['low_size'] <= book_winners_ofensiva]\n",
    "        book_loosers_ofensiva = low_size_novo.ticker.quantile(0.20)\n",
    "        book_loosers_ofensiva = low_size_novo[low_size_novo['low_size'] >= book_loosers_ofensiva]\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "        # DEFENSIVA\n",
    "\n",
    "        # low vol\n",
    "\n",
    "        # Low Vol direto do fechamento\n",
    "        low_vol_date_analysis = initial_date - pd.DateOffset(months=lookback_low_vol)\n",
    "        low_vol_prices = closing_price[(closing_price.index < initial_date) & (closing_price.index > low_vol_date_analysis)]\n",
    "\n",
    "        # Calcula volatilidade (desvio padrão dos retornos)\n",
    "        low_vol = low_vol_prices.pct_change().std()  # isso retorna uma Series com o ticker como índice\n",
    "        low_vol = low_vol.reset_index()\n",
    "        low_vol.columns = ['ticker', 'low_vol']\n",
    "\n",
    "        # Filtra para tickers do IBX\n",
    "        low_vol = low_vol[low_vol['ticker'].isin(ibx_tickers)]\n",
    "        low_vol = low_vol.sort_values(by='low_vol', ascending=True).reset_index(drop=True)\n",
    "\n",
    "        lista_low_vol = low_vol.ticker.tolist()\n",
    "\n",
    "\n",
    "        # quality\n",
    "        quality_date_analysis = initial_date - pd.DateOffset(months=lookback_quality)\n",
    "        quality = quality[(quality.index < initial_date) & (quality.index > quality_date_analysis)]\n",
    "        quality = quality.iloc[-1]\n",
    "        quality = quality.reset_index()\n",
    "        quality.columns = ['ticker','quality']\n",
    "        quality = quality[quality['ticker'].isin(ibx_tickers)]\n",
    "        quality = quality.sort_values(by='quality', ascending=False).reset_index(drop=True)\n",
    "\n",
    "\n",
    "        lista_quality = quality.ticker.tolist()\n",
    "\n",
    "        ## necessário implementar aqui os scores de cada ação, utilizando \n",
    "        # a soma dos índices da ação das duas listas/dataframes  \n",
    "\n",
    "        # acoes_25_quality_low_vol = ultimo_df['ticker'].quantile(0.75) # 25%\n",
    "        # acoes_25_quality_low_vol = ultimo_df[ultimo_df['ticker'] >= acoes_25_quality_low_vol]\n",
    "        # acoes_25_quality_low_vol = acoes_25_quality_low_vol['ticker'].tolist()\n",
    "\n",
    "        # value\n",
    "\n",
    "        value_date_analysis = initial_date - pd.DateOffset(months=lookback_value)\n",
    "        value = value[(value.index < initial_date) & (value.index > value_date_analysis)]\n",
    "        value = value.iloc[-1]\n",
    "        value = value.reset_index()\n",
    "        value.columns = ['ticker','quality']\n",
    "        value = value[value['ticker'].isin(ibx_tickers)]\n",
    "        value = value.sort_values(by='quality', ascending=False).reset_index(drop=True)\n",
    "\n",
    "\n",
    "        book_winners = momentum.ticker[:int(len(momentum)*0.4)]\n",
    "        book_loosers = [l for l in list(momentum['ticker']) if l not in list(book_winners)]\n",
    "        # ou \n",
    "        # book_losers = momentum.ticker[int(len(momentum))*0.4:]\n",
    "\n",
    "\n",
    "\n",
    "        # backtest é o mesmo para winners, losers e universe\n",
    "        # universe\n",
    "        backtest_universe = closing_price[(closing_price.index >= initial_date) & (closing_price.index < rebal)]\n",
    "        backtest_universe = backtest_universe.pct_change().replace(np.nan,0)\n",
    "        backtest_universe['Retorno'] = backtest_universe.mean(axis=1)\n",
    "        backtest_universe_ret = backtest_universe['Retorno'][1:]\n",
    "\n",
    "        # losers\n",
    "        backtest_loosers = closing_price[(closing_price.index >= initial_date) & (closing_price.index < rebal)]\n",
    "        backtest_loosers = backtest_loosers[book_loosers].pct_change().replace(np.nan,0)\n",
    "        backtest_loosers['Retorno'] = backtest_loosers.mean(axis=1)\n",
    "        backtest_loosers_ret = backtest_loosers['Retorno'][1:]\n",
    "\n",
    "        # winners\n",
    "        backtest_winners = closing_price[(closing_price.index >= initial_date) & (closing_price.index < rebal)]\n",
    "        backtest_winners = backtest_winners[book_winners].pct_change().replace(np.nan,0)\n",
    "        backtest_winners['Retorno'] = backtest_winners.mean(axis=1)\n",
    "        backtest_winners_ret = backtest_winners['Retorno'][1:]\n",
    "\n",
    "        # retorno\n",
    "        retorno_rebal = pd.DataFrame({\n",
    "            'Winners': backtest_winners_ret,\n",
    "            'Universo': backtest_universe_ret,\n",
    "            'Losers': backtest_loosers_ret,\n",
    "        })\n",
    "\n",
    "\n",
    "        returns = pd.concat([returns, retorno_rebal], ignore_index=False)\n",
    "\n",
    "        initial_date = initial_date + pd.DateOffset(months=rebal_time)\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "returns = returns.add(1).cumprod()\n",
    "\n",
    "\n",
    "qs.reports.full(returns['Winners'],returns['Universo'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f075799c",
   "metadata": {},
   "source": [
    "## Ponderação de Ofensiva e Defensiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b635619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# quero fazer um backtest com ponderação para o retorno, 80% do portifólio para defensiva e 20% para ofensiva\n",
    "# o mesmo para os winners e losers, 80% defensiva e 20% ofensiva\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
